// server/src/services/aiService.js
const { HfInference } = require('@huggingface/inference');
const ChatMessage = require('./jsonStorage'); // –ó–º—ñ–Ω–µ–Ω–æ –Ω–∞ JSON storage

const hf = new HfInference(process.env.HUGGINGFACE_API_KEY);

const WORKING_MODELS = {
  primary: 'meta-llama/Llama-3.2-3B-Instruct',
  fallback: 'microsoft/Phi-3-mini-4k-instruct',
  backup: 'HuggingFaceH4/zephyr-7b-beta'
};

class AIService {
  constructor() {
    this.currentModel = process.env.HUGGINGFACE_MODEL || WORKING_MODELS.primary;
  }

  getSystemPrompt() {
    return `–í–∏ - –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–∏–π –ø–æ–º—ñ—á–Ω–∏–∫ Pet Marketplace, –µ–∫—Å–ø–µ—Ä—Ç –∑ —Ç–≤–∞—Ä–∏–Ω.
–ó–∞–≤–¥–∞–Ω–Ω—è:
1. –î–æ–ø–æ–º–∞–≥–∞—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º –∑–Ω–∞–π—Ç–∏ —ñ–¥–µ–∞–ª—å–Ω—É –¥–æ–º–∞—à–Ω—é —Ç–≤–∞—Ä–∏–Ω—É
2. –î–∞—Ç–∏ –ø–æ—Ä–∞–¥–∏ —â–æ–¥–æ –¥–æ–≥–ª—è–¥—É –∑–∞ —Ç–≤–∞—Ä–∏–Ω–∞–º–∏
3. –†–æ–∑–ø–æ–≤—ñ—Å—Ç–∏ –ø—Ä–æ —Ä—ñ–∑–Ω—ñ –ø–æ—Ä–æ–¥–∏
4. –ü–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–≤–∞—Ç–∏ –ø—Ä–∏—Ç—É–ª–∫–∏ –∞–±–æ —Ä–æ–∑–≤—ñ–¥–Ω–∏–∫—ñ–≤
5. –í—ñ–¥–ø–æ–≤—ñ–¥–∞—Ç–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é

–ë—É–¥—å—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω—ñ, —Å—Ç–∏—Å–ª—ñ (–¥–æ 250 —Å–ª—ñ–≤) —Ç–∞ –ø—Ä–∞–∫—Ç–∏—á–Ω—ñ.`;
  }

  async getContext(userId, sessionId, limit = 5) {
    try {
      const history = await ChatMessage.find({
        userId: String(userId),
        sessionId: String(sessionId)
      });

      const sorted = ChatMessage.sort(history, 'timestamp', -1);
      const limited = ChatMessage.limit(sorted, limit);
      const reversed = limited.reverse();

      return reversed.map(msg => ({
        role: msg.userMessage ? 'user' : 'assistant',
        content: msg.userMessage || msg.botResponse
      }));
    } catch (error) {
      console.error('Context fetch error:', error.message);
      return [];
    }
  }

  async callHfAPI(messages, model) {
    try {
    const MODEL_TASK = {
    'meta-llama/Llama-3.2-3B-Instruct': 'conversational',
    'HuggingFaceH4/zephyr-7b-beta': 'conversational',
    'microsoft/Phi-3-mini-4k-instruct': 'text-generation'
    };

    const preferredTask = MODEL_TASK[model] || 'auto';

    if (preferredTask === 'conversational') {
    const response = await hf.chatCompletion({ model, messages, max_tokens: 300, temperature: 0.7 });
    return response.choices[0].message.content;
    }

    if (preferredTask === 'text-generation') {
    const prompt = messages.map(m => `${m.role}: ${m.content}`).join('\n') + '\nassistant:';
    const result = await hf.textGeneration({ model, inputs: prompt, parameters: { max_new_tokens: 300, temperature: 0.7, return_full_text: false } });
    return result.generated_text.replace(prompt, '').trim();
    }

    try {
    const response = await hf.chatCompletion({ model, messages, max_tokens: 300, temperature: 0.7 });
    return response.choices[0].message.content;
    } catch (chatErr) {
    try {
    const prompt = messages.map(m => `${m.role}: ${m.content}`).join('\n') + '\nassistant:';
    const result = await hf.textGeneration({ model, inputs: prompt, parameters: { max_new_tokens: 300, temperature: 0.7, return_full_text: false } });
    return result.generated_text.replace(prompt, '').trim();
    } catch (textErr) {
    const finalErr = textErr.message || chatErr.message || 'Unknown HF error';
    throw new Error(finalErr);
    }
    }
    } catch (error) {
    throw error;
    }
  }

  async getAIResponse(userMessage, userId, sessionId, context = {}) {
    try {
      const chatHistory = await this.getContext(userId, sessionId);
      const systemContext = this.getSystemPrompt();
      
      const messages = [
        { role: 'system', content: systemContext },
        ...chatHistory,
        { role: 'user', content: userMessage }
      ];

      let botMessage = '';
      const modelsToTry = [
        this.currentModel,
        WORKING_MODELS.primary,
        WORKING_MODELS.fallback,
        WORKING_MODELS.backup
      ];

      const uniqueModels = [...new Set(modelsToTry)];

      for (const model of uniqueModels) {
        try {
          console.log(`ü§ñ Trying model: ${model}`);
          botMessage = await this.callHfAPI(messages, model);
          
          if (botMessage && botMessage.trim().length > 10) {
            this.currentModel = model;
            console.log(`‚úÖ Success with model: ${model}`);
            break;
          }
        } catch (err) {
          console.warn(`‚ùå Model ${model} failed:`, err.message);
          continue;
        }
      }

      if (!botMessage || botMessage.trim().length < 10) {
        botMessage = '–í–∏–±–∞—á—Ç–µ, –≤–∏–Ω–∏–∫–ª–∞ —Ç–µ—Ö–Ω—ñ—á–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ –∑ AI. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –∫—ñ–ª—å–∫–∞ —Å–µ–∫—É–Ω–¥ –∞–±–æ –∑–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏.';
      }

      botMessage = botMessage
        .replace(/<\|.*?\|>/g, '')
        .replace(/assistant:/gi, '')
        .replace(/user:/gi, '')
        .trim();

      if (botMessage.length > 500) {
        const lastPeriod = botMessage.lastIndexOf('.', 500);
        botMessage = lastPeriod > 300 
          ? botMessage.substring(0, lastPeriod + 1)
          : botMessage.substring(0, 500) + '...';
      }

      await ChatMessage.create({
        userId: String(userId),
        sessionId: String(sessionId),
        userMessage,
        botResponse: botMessage,
        context
      });

      return botMessage;
    } catch (error) {
      console.error('AI Service Error:', error.message);
      
      if (error.message.includes('401') || error.message.includes('Unauthorized')) {
        throw new Error('–ü–æ–º–∏–ª–∫–∞ API –∫–ª—é—á–∞. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ HUGGINGFACE_API_KEY –≤ .env —Ñ–∞–π–ª—ñ');
      }
      
      const fallbackMessage = '–ù–∞ –∂–∞–ª—å, AI —Å–µ—Ä–≤—ñ—Å —Ç–∏–º—á–∞—Å–æ–≤–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π. –ë—É–¥—å –ª–∞—Å–∫–∞, —Å–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ –∞–±–æ –Ω–∞–ø–∏—à—ñ—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–µ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ —Ç–≤–∞—Ä–∏–Ω.';
      
      try {
        await ChatMessage.create({
          userId: String(userId),
          sessionId: String(sessionId),
          userMessage,
          botResponse: fallbackMessage,
          context
        });
      } catch (dbError) {
        console.error('Storage Error:', dbError.message);
      }
      
      return fallbackMessage;
    }
  }

  async recommendPet(answers) {
    const messages = [
      {
        role: 'system',
        content: '–í–∏ - –µ–∫—Å–ø–µ—Ä—Ç –∑ —Ç–≤–∞—Ä–∏–Ω. –î–∞–π—Ç–µ –∫–æ—Ä–æ—Ç–∫—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó.'
      },
      {
        role: 'user',
        content: `–ü–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π 3 –ø–æ—Ä–æ–¥–∏ —Ç–≤–∞—Ä–∏–Ω –Ω–∞ –æ—Å–Ω–æ–≤—ñ:
- –¢–≤–∞—Ä–∏–Ω–∞: ${answers.petType}
- –ü–æ–º–µ—à–∫–∞–Ω–Ω—è: ${answers.houseSize}
- –ß–∞—Å: ${answers.timeAvailable}
- –ë—é–¥–∂–µ—Ç: ${answers.budget}
- –°—ñ–º'—è: ${answers.familyType}

–ö–æ—Ä–æ—Ç–∫–æ –ø—Ä–æ –∫–æ–∂–Ω—É –ø–æ—Ä–æ–¥—É (2-3 —Ä–µ—á–µ–Ω–Ω—è).`
      }
    ];

    try {
      return await this.callHfAPI(messages, this.currentModel);
    } catch (error) {
      console.error('Recommend pet error:', error);
      return '–í–∏–±–∞—á—Ç–µ, –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ.';
    }
  }

    async classifyQuery(text) {
    const lowerText = text.toLowerCase();

    let category = 'general';
    let petType = 'none';

    if (lowerText.includes('—Ä–µ–∫–æ–º–µ–Ω–¥') || lowerText.includes('–ø–æ—Ä–∞–¥') || lowerText.includes('–ø—ñ–¥—ñ–π–¥–µ')) {
      category = 'recommendation';
    } else if (lowerText.includes('–¥–æ–≥–ª—è–¥') || lowerText.includes('–≥–æ–¥—É–≤–∞—Ç') || lowerText.includes('–∫–æ—Ä–º') || lowerText.includes('–ª—ñ–∫—É–≤–∞–Ω') || lowerText.includes('–ª—ñ–∫—É–≤–∞')) {
      category = 'care';
    } else if (lowerText.includes('–ø–æ—Ä–æ–¥') || lowerText.includes('—Ä—ñ–∑–Ω–∏—Ü—è')) {
      category = 'breed';
    } else if (lowerText.includes('–ø—Ä–∏—Ç—É–ª–æ–∫') || lowerText.includes('–¥–µ –∫—É–ø–∏—Ç–∏') || lowerText.includes('–∑–∞–≤–æ–¥—á–∏–∫') || lowerText.includes('–∑–∞–≤–æ–¥–Ω–∏–∫')) {
      category = 'shelter';
    }

    if (lowerText.includes('—Å–æ–±–∞–∫') || lowerText.includes('–ø–µ—Å') || lowerText.includes('–ø–µ—Å–∏–∫')) {
      petType = 'dog';
    } else if (lowerText.includes('–∫—ñ—Ç') || lowerText.includes('–∫—ñ—à–∫') || lowerText.includes('–∫–æ—Ç')) {
      petType = 'cat';
    } else if (lowerText.includes('–ø—Ç–∞—Ö') || lowerText.includes('—Ö–æ–º') || lowerText.includes('—Ä–∏–±')) {
      petType = 'other';
    }

    return {
      category,
      petType,
      confidence: 0.8
    };
  }
}

module.exports = new AIService();